<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mobile Speaking Speed Test</title>
    <style>
        /* Basic reset and box-sizing */
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: flex-start; 
            min-height: 100vh; 
            background-color: #f0f2f5;
            padding: 20px 10px; 
            text-align: center;
            font-size: 16px; 
        }
        .container {
            background-color: #fff;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
            width: 100%; 
            max-width: 500px; 
        }
        h1 {
            color: #333;
            font-size: 1.5em; 
            margin-bottom: 15px;
        }
        .instructions {
            margin-bottom: 20px;
            color: #555;
            font-size: 0.9em;
            line-height: 1.5;
        }
        .controls { 
            display: flex;
            flex-direction: column; 
            gap: 10px; 
            margin-bottom: 20px; 
        }
        .controls button {
            background-color: #007bff;
            color: white;
            border: none;
            padding: 15px 20px; 
            text-align: center;
            text-decoration: none;
            display: block; 
            width: 100%;
            font-size: 1em;
            cursor: pointer;
            border-radius: 8px;
            transition: background-color 0.3s;
            font-weight: bold;
        }
        .controls button:hover:not(:disabled) {
            background-color: #0056b3;
        }
        .controls button:disabled {
            background-color: #ccc;
            cursor: not-allowed;
            opacity: 0.7;
        }
        #stopButton { 
            background-color: #dc3545;
        }
        #stopButton:hover:not(:disabled) {
            background-color: #c82333;
        }
        .status {
            margin-top: 20px; 
            font-weight: bold;
            min-height: 24px; 
            font-size: 1em;
        }
        .status.listening { color: #28a745; }
        .status.processing { color: #ffc107; }
        .status.error { color: #dc3545; }

        .transcript-container {
            margin-top: 20px;
            padding: 15px;
            border: 1px solid #ddd;
            border-radius: 8px;
            background-color: #f9f9f9;
            min-height: 80px; 
            max-height: 200px; 
            overflow-y: auto; 
            text-align: left;
            line-height: 1.6;
            word-break: break-word; 
        }
        .transcript-container strong {
            display: block;
            margin-bottom: 8px;
            color: #333;
            font-size: 0.9em;
        }
        .transcript-container p {
            font-style: italic;
            color: #444;
            font-size: 0.95em;
        }
        .results {
            margin-top: 20px;
            font-size: 1.1em;
            line-height: 1.6;
        }
        .results span {
            font-weight: bold;
            color: #007bff;
        }
        .compatibility-notice {
            margin-top: 25px;
            font-size: 0.8em;
            color: #6c757d;
            margin-bottom: 20px; /* Added margin for spacing before debug log */
        }
        /* Styles for on-screen debug log */
        #debugLogContainer {
            margin-top: 20px;
            padding: 10px;
            border: 1px dashed #ccc;
            background-color: #f8f8f8;
            text-align: left;
            font-size: 0.8em;
            max-height: 300px;
            overflow-y: auto;
            line-height: 1.4;
            word-break: break-all;
        }
        #debugLogContainer h3 {
            margin-top: 0;
            font-size: 1.1em;
        }
        #debugLogContainer p {
            margin: 2px 0;
            border-bottom: 1px solid #eee;
            padding-bottom: 2px;
        }
        #clearLogButton {
            margin-top: 10px;
            padding: 8px 12px;
            font-size: 0.9em;
            cursor: pointer;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Speaking Speed Test</h1>

        <div class="instructions">
            <p>Tap "Start Speaking" and talk into your phone. Your words will appear below. Tap "Stop & Calculate" when done.</p>
        </div>

        <div class="controls">
            <button id="startButton">Start Speaking</button>
            <button id="stopButton" disabled>Stop & Calculate</button>
        </div>

        <div id="status" class="status">Ready.</div>
        <p>Words Per Minute: <span id="wpm">0</span></p> 

        <div class="transcript-container">
            <strong>Recognized Text:</strong>
            <p id="transcriptOutput">...</p>
        </div>

        <div id="results" class="results"></div>

        <div class="compatibility-notice">
            Uses your browser's Speech Recognition. Works best in Chrome (Android) or Safari (iOS). Grant microphone access.
        </div>

        <!-- On-screen Debug Log Area -->
        <button id="clearLogButton">Clear On-Screen Log</button>
        <div id="debugLogContainer">
            <h3>Debug Log:</h3>
            <!-- Log messages will be appended here -->
        </div>
    </div>

    <script>
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const statusDiv = document.getElementById('status');
        const transcriptOutput = document.getElementById('transcriptOutput');
        const resultsDiv = document.getElementById('results');
        const wpmSpan = document.getElementById('wpm'); 
        const debugLogContainer = document.getElementById('debugLogContainer');
        const clearLogButton = document.getElementById('clearLogButton');

        // Function to log messages to the on-screen div
        function logToScreen(message) {
            const logEntry = document.createElement('p');
            const now = new Date();
            const timeString = `${now.getHours()}:${String(now.getMinutes()).padStart(2, '0')}:${String(now.getSeconds()).padStart(2, '0')}.${String(now.getMilliseconds()).padStart(3, '0')}`;
            logEntry.textContent = `[${timeString}] ${message}`;
            // Prepend to see latest logs first
            if (debugLogContainer.children.length > 1) { // first child is H3
                debugLogContainer.insertBefore(logEntry, debugLogContainer.children[1]);
            } else {
                debugLogContainer.appendChild(logEntry);
            }
            // Also log to console for desktop debugging
            console.log(message);
        }

        clearLogButton.addEventListener('click', () => {
            // Remove all <p> elements from log container
            const logEntries = debugLogContainer.querySelectorAll('p');
            logEntries.forEach(entry => entry.remove());
            logToScreen("On-screen log cleared.");
        });

        let recognition;
        let startTime;
        let accumulatedFinalTranscript = ''; 
        let currentInterimTranscript = ''; 
        let isRecognizing = false;

        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

        if (!SpeechRecognition) {
            const msg = "Speech Recognition not supported. Try Chrome or Safari.";
            statusDiv.textContent = msg;
            statusDiv.className = 'status error';
            startButton.disabled = true;
            stopButton.disabled = true;
            logToScreen(msg);
        } else {
            recognition = new SpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US';

            recognition.onstart = () => {
                isRecognizing = true;
                const msg = "Recognition started, accumulatedFinalTranscript reset.";
                statusDiv.textContent = "Listening... Speak now!";
                statusDiv.className = 'status listening';
                startButton.disabled = true;
                stopButton.disabled = false;
                resultsDiv.textContent = '';
                transcriptOutput.textContent = '...';
                wpmSpan.textContent = '0';
                accumulatedFinalTranscript = ''; 
                currentInterimTranscript = '';
                startTime = new Date();
                logToScreen(`${msg} Start time: ${startTime.toISOString()}`);
            };

            recognition.onresult = (event) => {
                if (!isRecognizing) {
                    logToScreen("onresult fired but not recognizing, ignoring.");
                    return;
                }
                logToScreen(`onresult triggered. Results length: ${event.results.length}, Result index: ${event.resultIndex}`);
                let latest_interim_for_display = '';
                let latest_final_transcript_this_event = ''; // Store the latest final transcript from this event

                for (let i = 0; i < event.results.length; ++i) { // Iterate all results, not just from event.resultIndex
                    const result = event.results[i];
                    const transcript_segment = result[0].transcript;

                    if (result.isFinal) {
                        // The latest segment in event.results that isFinal is the most complete current final version
                        latest_final_transcript_this_event = transcript_segment.trim();
                        logToScreen(`Segment ${i} (final) considered: "${latest_final_transcript_this_event}"`);
                    } else {
                        latest_interim_for_display += transcript_segment;
                    }
                }

                // If a new final transcript was found in this event, it becomes THE accumulatedFinalTranscript
                if (latest_final_transcript_this_event.length > 0) {
                    accumulatedFinalTranscript = latest_final_transcript_this_event;
                    logToScreen(`Updated accumulatedFinalTranscript (REPLACED): "${accumulatedFinalTranscript}"`);
                }
                
                currentInterimTranscript = latest_interim_for_display.trim();
                // Log interim only once per event if it changes to reduce noise
                // This check might need adjustment if interim updates frequently without actual change
                // For now, simple logging:
                if (currentInterimTranscript.length > 0) {
                     logToScreen(`Current interim display update: "${currentInterimTranscript}"`);
                }
                
                transcriptOutput.textContent = accumulatedFinalTranscript + 
                    (currentInterimTranscript ? (accumulatedFinalTranscript ? ' ' : '') + currentInterimTranscript : '');
            };
            recognition.onend = () => {
                isRecognizing = false;
                logToScreen("Recognition ended.");
                statusDiv.textContent = "Processing complete. Tap Start to try again.";
                statusDiv.className = 'status';
                startButton.disabled = false;
                stopButton.disabled = true;

                let textForCalculation = accumulatedFinalTranscript.trim();
                logToScreen(`Final text for calculation: "${textForCalculation}"`);
                
                if (textForCalculation === '' && currentInterimTranscript.trim().length > 3) { 
                     logToScreen(`WARN: Fallback considered for interim: "${currentInterimTranscript.trim()}" (Not used by default)`);
                }

                transcriptOutput.textContent = textForCalculation || 'No speech detected.';

                if (textForCalculation === '') {
                     resultsDiv.innerHTML = "No clear speech was finalized. Try speaking clearly.";
                     wpmSpan.textContent = '0';
                     logToScreen("No text for WPM calc.");
                     return;
                }

                const endTime = new Date();
                const timeDiffSeconds = (endTime - startTime) / 1000;
                logToScreen(`Start time: ${startTime.toISOString()}, End time: ${endTime.toISOString()}, Diff (s): ${timeDiffSeconds.toFixed(3)}`);

                if (timeDiffSeconds < 1.0) { 
                    resultsDiv.innerHTML = `Duration ${timeDiffSeconds.toFixed(2)}s. Too short for reliable WPM. <br>Recognized: "${textForCalculation}"`;
                    wpmSpan.textContent = '0';
                    logToScreen(`Duration too short: ${timeDiffSeconds.toFixed(3)}s`);
                    return;
                }

                const words = textForCalculation.split(/\s+/).filter(word => word && word.length > 0);
                const wordCount = words.length;
                logToScreen(`Words for calculation: [${words.join(', ')}]`);
                logToScreen(`Word count: ${wordCount}`);

                if (wordCount > 0) {
                    const calculatedWpm = Math.round((wordCount / timeDiffSeconds) * 60);
                    wpmSpan.textContent = calculatedWpm;
                    resultsDiv.innerHTML = `
                        Duration: <span>${timeDiffSeconds.toFixed(2)}s</span><br>
                        Word Count: <span>${wordCount}</span><br>
                        Your Speed: <span>${calculatedWpm} WPM</span>
                    `;
                    logToScreen(`Calculated WPM: ${calculatedWpm}`);
                } else {
                    wpmSpan.textContent = '0';
                    resultsDiv.innerHTML = "No words clearly finalized for calculation.";
                    logToScreen("No words counted for WPM.");
                }
                accumulatedFinalTranscript = '';
                currentInterimTranscript = '';
            };

            recognition.onerror = (event) => {
                isRecognizing = false;
                const errMsg = `Recognition error: ${event.error} - ${event.message || '(no message)'}`;
                logToScreen(errMsg);
                console.error("Full error object:", event); // For desktop
                
                let displayMessage = "Error: " + event.error;
                if (event.error === 'no-speech') {
                    displayMessage = "No speech detected. Check microphone.";
                } else if (event.error === 'audio-capture') {
                    displayMessage = "Mic capture failed. Ensure it's not in use.";
                } else if (event.error === 'not-allowed') {
                    displayMessage = "Mic access denied. Please allow in settings.";
                }
                statusDiv.textContent = displayMessage;
                statusDiv.className = 'status error';
                startButton.disabled = false;
                stopButton.disabled = true;
                accumulatedFinalTranscript = '';
                currentInterimTranscript = '';
                wpmSpan.textContent = '0';
            };
            logToScreen("SpeechRecognition initialized.");
        }

        startButton.addEventListener('click', () => {
            if (!recognition) return;
            if (isRecognizing) {
                logToScreen("Start clicked while recognizing, stopping first.");
                recognition.stop(); 
                return;
            }
            try {
                logToScreen("Attempting to start recognition via button click...");
                accumulatedFinalTranscript = ''; 
                currentInterimTranscript = '';
                transcriptOutput.textContent = '...';
                resultsDiv.textContent = '';
                wpmSpan.textContent = '0';
                
                recognition.start();
            } catch(e) {
                const errMsg = `Error starting recognition from button: ${e.name} - ${e.message}`;
                logToScreen(errMsg);
                statusDiv.className = 'status error';
                if (e.name === 'InvalidStateError') {
                    statusDiv.textContent = "Recognition busy. Try again shortly.";
                } else {
                    statusDiv.textContent = "Error starting. Check mic permission.";
                }
                startButton.disabled = false; 
                stopButton.disabled = true;
                isRecognizing = false; 
            }
        });

        stopButton.addEventListener('click', () => {
            if (!recognition || !isRecognizing) return;
            logToScreen("Stop button clicked, stopping recognition.");
            recognition.stop();
            statusDiv.textContent = "Stopping and calculating...";
            statusDiv.className = 'status processing';
        });

        logToScreen("Script loaded. Ready.");
    </script>
</body>
</html>
