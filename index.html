    <script>
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const statusDiv = document.getElementById('status');
        const transcriptOutput = document.getElementById('transcriptOutput');
        const resultsDiv = document.getElementById('results');
        const wpmSpan = document.getElementById('wpm');

        let recognition;
        let startTime;
        let final_transcript_segments = [];
        let accumulatedFinalTranscript = '';
        let currentInterimTranscript = '';
        let isRecognizing = false; // Flag to track recognition state

        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

        if (!SpeechRecognition) {
            statusDiv.textContent = "Speech Recognition not supported. Try Chrome or Safari.";
            statusDiv.className = 'status error';
            startButton.disabled = true;
            stopButton.disabled = true;
        } else {
            recognition = new SpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US';

            recognition.onstart = () => {
                console.log("Recognition started");
                isRecognizing = true;
                statusDiv.textContent = "Listening... Speak now!";
                statusDiv.className = 'status listening';
                startButton.disabled = true;
                stopButton.disabled = false;
                resultsDiv.textContent = '';
                transcriptOutput.textContent = '...';
                wpmSpan.textContent = '0';
                accumulatedFinalTranscript = '';
                currentInterimTranscript = '';
                final_transcript_segments = [];
                startTime = new Date();
                console.log("Start time:", startTime);
            };

            recognition.onresult = (event) => {
                if (!isRecognizing) return; // Prevent processing if recognition has been stopped

                console.log("onresult event:", event);
                let latest_interim_for_display = '';

                // It's safer to rebuild final_transcript_segments each time
                // to handle cases where the API might revise earlier segments.
                let current_final_segments_map = new Map();

                for (let i = 0; i < event.results.length; ++i) {
                    const result = event.results[i];
                    const transcript_from_result = result[0].transcript.trim();

                    if (result.isFinal) {
                        // Use resultIndex as a key to ensure each segment is stored once
                        // This assumes resultIndex is consistent for a given utterance segment
                        current_final_segments_map.set(i, transcript_from_result);
                        console.log(`Segment ${i} (final): ${transcript_from_result}`);
                    } else {
                        if (i === event.results.length - 1) { // Only the last one is truly interim for display
                            latest_interim_for_display = transcript_from_result;
                            console.log(`Segment ${i} (interim): ${latest_interim_for_display}`);
                        }
                    }
                }
                
                // Sort map keys (indices) to ensure correct order before joining
                final_transcript_segments = Array.from(current_final_segments_map.keys())
                                              .sort((a, b) => a - b)
                                              .map(key => current_final_segments_map.get(key));

                const complete_final_text = final_transcript_segments.join(' ');
                console.log("Current complete_final_text:", complete_final_text);

                accumulatedFinalTranscript = complete_final_text;
                currentInterimTranscript = latest_interim_for_display;

                transcriptOutput.textContent = complete_final_text +
                    (currentInterimTranscript ? (complete_final_text ? ' ' : '') + currentInterimTranscript : '');
            };

            recognition.onend = () => {
                console.log("Recognition ended");
                isRecognizing = false; // Mark as not recognizing
                statusDiv.textContent = "Processing complete. Tap Start to try again.";
                statusDiv.className = 'status';
                startButton.disabled = false;
                stopButton.disabled = true;

                // Give a very brief moment for any final onresult to potentially process
                // This is a bit of a hack, ideally onend implies all results are in.
                // setTimeout(() => { 
                    let textForCalculation = accumulatedFinalTranscript.trim();
                    console.log("Final accumulatedFinalTranscript for calculation:", textForCalculation);
                    console.log("CurrentInterimTranscript at onend:", currentInterimTranscript.trim());

                    // If no final text, but there was a robust interim when stopped.
                    // Be cautious with this, as interim can be unreliable.
                    if (textForCalculation === '' && currentInterimTranscript.trim().length > 0) {
                        console.log("Using currentInterimTranscript as fallback for calculation.");
                        // textForCalculation = currentInterimTranscript.trim(); // Decide if you want this fallback
                    }

                    transcriptOutput.textContent = textForCalculation || 'No speech detected.';

                    if (textForCalculation === '') {
                        resultsDiv.innerHTML = "No clear speech was finalized. <br>Try speaking clearly.";
                        wpmSpan.textContent = '0';
                        return;
                    }

                    const endTime = new Date();
                    console.log("End time:", endTime);
                    const timeDiffSeconds = (endTime - startTime) / 1000;
                    console.log("Time difference (seconds):", timeDiffSeconds);

                    // Add a stricter minimum duration for WPM calculation
                    if (timeDiffSeconds < 0.8) { // Increased minimum duration
                        resultsDiv.innerHTML = `Duration ${timeDiffSeconds.toFixed(2)}s. Too short for reliable WPM. <br>Recognized: "${textForCalculation}"`;
                        wpmSpan.textContent = '0';
                        console.log("Duration too short for WPM calculation.");
                        return;
                    }

                    const words = textForCalculation.split(/\s+/).filter(word => word.length > 0);
                    const wordCount = words.length;
                    console.log("Word count:", wordCount);

                    if (wordCount > 0) {
                        const calculatedWpm = Math.round((wordCount / timeDiffSeconds) * 60);
                        wpmSpan.textContent = calculatedWpm;
                        resultsDiv.innerHTML = `
                            Duration: <span>${timeDiffSeconds.toFixed(2)}s</span><br>
                            Word Count: <span>${wordCount}</span><br>
                            Your Speed: <span>${calculatedWpm} WPM</span>
                        `;
                        console.log("Calculated WPM:", calculatedWpm);
                    } else {
                        wpmSpan.textContent = '0';
                        resultsDiv.innerHTML = "No words clearly finalized for calculation.";
                        console.log("No words for WPM calculation.");
                    }
                // }, 100); // Delay for setTimeout, if used
            };

            recognition.onerror = (event) => {
                console.error("Recognition error:", event);
                isRecognizing = false;
                let errorMessage = "Error: " + event.error;
                if (event.error === 'no-speech') {
                    errorMessage = "No speech detected. Check microphone.";
                } else if (event.error === 'audio-capture') {
                    errorMessage = "Mic capture failed. Ensure it's not in use.";
                } else if (event.error === 'not-allowed') {
                    errorMessage = "Mic access denied. Please allow in settings.";
                }
                statusDiv.textContent = errorMessage;
                statusDiv.className = 'status error';
                startButton.disabled = false;
                stopButton.disabled = true;
                accumulatedFinalTranscript = '';
                currentInterimTranscript = '';
                final_transcript_segments = [];
                wpmSpan.textContent = '0';
            };
        }

        startButton.addEventListener('click', () => {
            if (!recognition) return;
            if (isRecognizing) { // If already recognizing, stop it first
                console.log("Start clicked while recognizing, stopping first.");
                recognition.stop(); // This should trigger onend, then user can click start again
                return;
            }
            try {
                console.log("Attempting to start recognition...");
                // Reset states explicitly here too
                accumulatedFinalTranscript = '';
                currentInterimTranscript = '';
                transcriptOutput.textContent = '...';
                resultsDiv.textContent = '';
                wpmSpan.textContent = '0';
                final_transcript_segments = [];
                
                recognition.start();
            } catch(e) {
                console.error("Error starting recognition from button:", e);
                statusDiv.className = 'status error';
                if (e.name === 'InvalidStateError') {
                    statusDiv.textContent = "Recognition busy. Try again shortly.";
                } else {
                    statusDiv.textContent = "Error starting. Check mic permission.";
                }
                startButton.disabled = false;
                stopButton.disabled = true;
                isRecognizing = false; // Ensure flag is reset
            }
        });

        stopButton.addEventListener('click', () => {
            if (!recognition || !isRecognizing) return;
            console.log("Stop button clicked, stopping recognition.");
            recognition.stop();
            statusDiv.textContent = "Stopping and calculating...";
            statusDiv.className = 'status processing';
        });
    </script>
</body>
</html>
